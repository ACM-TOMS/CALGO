% workaround (https://tex.stackexchange.com/questions/239444/sideways-table-not-centered-in-the-page)
\RequirePackage[counterclockwise]{rotating}
\documentclass[format=acmsmall,review=false, screen=true]{acmart}

\usepackage{booktabs} % For formal tables

\usepackage{pgfplots}
\pgfplotsset{compat=1.14}
\usepgfplotslibrary{statistics}
\usepgfplotslibrary{colorbrewer}
\usepackage{xcolor}

\usetikzlibrary{external}
\tikzexternalize[prefix=figures/]

\usepackage{multirow}
\usepackage{units}
\usepackage[normalem]{ulem}

% TOG prefers author-name bib system with square brackets
\citestyle{acmauthoryear}
\setcitestyle{square}


\usepackage[ruled,linesnumbered]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}	
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

\usepackage{subcaption}


% Metadata Information
\acmJournal{TOMS}
%\acmVolume{9}
%\acmNumber{4}
%\acmArticle{39}
%\acmYear{2010}
%\acmMonth{3}
%\copyrightyear{2009}

%\acmArticleSeq{9}

% Copyright
%\setcopyright{acmcopyright}
\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
\acmPrice{15.00}
\acmDOI{10.1145/3442348}

% Paper history
\received{June 2018}
\received[revised]{July 2019}
\received[revised]{June 2020}
\received[revised]{November 2020}
\received[accepted]{December 2020}

%\input{defs.tex}

% Document starts
\begin{document}
% Title portion. Note the short title for running heads
\title[Algorithm XXX: A Fast Scalable Solver for the Dense Linear (Sum) Assignment Problem]{Algorithm XXX: A Fast Scalable Solver for the Dense Linear (Sum) Assignment Problem}

\author{Stefan Guthe}
\email{stefan.guthe@tu-darmstadt.de}
\orcid{0000-0001-5539-9096}
\affiliation{\institution{TU Darmstadt}\department{Graphical Interactive Systems Group}\streetaddress{Fraunhofer Str. 5}\postcode{64283}\city{Darmstadt}\country{Germany}}
\affiliation{\institution{Fraunhofer IGD}\country{Germany}}

\author{Daniel Thuerck}
\email{daniel.thuerck@neclab.eu}
\affiliation{\institution{NEC Laboratories}\country{Germany}}
%\affiliation{\institution{TU Darmstadt}\country{Germany}}
\authornote{Work done while at TU Darmstadt.}

\acmSubmissionID{TOMS-2018-0046}

\renewcommand\shortauthors{Guthe, S., Thuerck, D.}

\begin{abstract}
This document contains the instructions for building and testing the software bundle as well as instructions on how to use the software in your own project.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
 \begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002950.10003624.10003625.10003628</concept_id>
<concept_desc>Mathematics of computing~Combinatorial algorithms</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10002950.10003624.10003625.10003630</concept_id>
<concept_desc>Mathematics of computing~Combinatorial optimization</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Mathematics of computing~Combinatorial algorithms}
\ccsdesc[500]{Mathematics of computing~Combinatorial optimization}
%
% End generated code
%

\keywords{Successive Shortest Path Algorithm, Parallel Processing, Epsilon Scaling}

\maketitle

\section{Linux}
\label{sec:linux}
This section contains the instructions for building and running under Linux. For Windows, refer to Section \ref{sec:windows}.

\subsection{Requirements}
The following software is required to build the source code that comes with this publication:
\begin{itemize}
\item CMake 3.5
\item GCC
\item CUDA 10 (or later, optional for the GPU build)
\end{itemize}

\subsection{Build Instructions}
To build the test package that was used to generate all the performance measurements in the main publication, run the following commands inside the \texttt{lap\_solver} directory:
\begin{itemize}
\item \small{\texttt{mkdir build}}
\item \small{\texttt{cd build}}
\item \small{\texttt{cmake ../gcc}}
\item \small{\texttt{make}}
\end{itemize}
Since the makefile is set up to compile the same code with multiple sets of defines, it is not possible to use the parallel build, e.g. \texttt{make -j4}, as this will cause the build to fail.

\section{Windows}
\label{sec:windows}

\subsection{Requirements}
The following software is required to build the source code that comes with this publication:
\begin{itemize}
\item Visual Studio (at least Community Edition) 2014, 2017 or 2019
\item CUDA 10.2 (other versions require build files to be patched manually)
\end{itemize}

\subsection{Build Instructions}
To build the test package that was used to generate all the performance measurements in the main publication, the following steps are required:
\begin{itemize}
\item load solution from \texttt{vc14}, \texttt{vc17} or \texttt{vc19}
\item press \texttt{Ctrl+Shift+B}
\end{itemize}

\section{Running Tests}
The following commands will re-produce the data found in the figures and tables of the paper (Figure 1, 2 \& 3 require special debug builds) using Linux. For Windows, the relative path is different (\texttt{../../../../../images/}, when executing in the build directory).
\begin{itemize}
\raggedright
\item Table 1 \& Figure 4:\\
\small{\texttt{./test\_cpu\_evaluated -table\_min 1000 -table\_max 32000 -sanity -random -geometric -geometric\_disjoint -random\_low\_rank -rank\_min 1 -rank\_max 8 -double -single -runs 5 -omp}\\
\texttt{./test\_cpu\_evaluated -table\_min 1000 -table\_max 128000 -sanity -random -geometric -geometric\_disjoint -random\_low\_rank -rank\_min 1 -rank\_max 8 -double -epsilon -runs 5 -omp}}
\item Figure 5:\\
\small{\texttt{./test\_cpu -table\_min 1000 -table\_max 32000 -sanity -geometric\_disjoint -random\_low\_rank -rank\_min 1 -rank\_max 8 -double -single -runs 5}\\
\texttt{./test\_cpu -table\_min 1000 -table\_max 128000 -random -geometric -double -single -runs 5}\\
\texttt{./test\_cpu -table\_min 1000 -table\_max 128000 -sanity -random -geometric\\ -geometric\_disjoint  -random\_low\_rank -rank\_min 1 -rank\_max 8\\ -double -epsilon -runs 5}}
\item Figure 6:\\
\small{\texttt{./test\_cpu -memory 257698037760 -cached\_min 1000 -cached\_max 1024000 -geometric\_cached -geometric\_disjoint\_cached -sanity\_cached -random\_low\_rank\_cached -rank\_min 1 -rank\_max 8 -double -epsilon -runs 5 -omp}}
\item Figure 7:\\
\small{\texttt{./test\_gpu -memory 3221225472 -table\_min 1000 -table\_max 128000 -random -double -epsilon -runs 5}\\
\texttt{./test\_gpu -memory 3221225472 -cached\_min 1000 -cached\_max 1024000 -geometric\_cached -geometric\_disjoint\_cached -sanity\_cached -random\_low\_rank\_cached -rank\_min 1 -rank\_max 8 -double -epsilon -runs 5}}
\item Figure 8:\\
\small{\texttt{./test\_gpu -memory 15032385536 -table\_min 1000 -table\_max 128000 -random -double -epsilon -runs 5}\\
\texttt{./test\_gpu -memory 15032385536 -cached\_min 1000 -cached\_max 1024000 -geometric\_cached -geometric\_disjoint\_cached -sanity\_cached -random\_low\_rank\_cached -rank\_min 1 -rank\_max 8 -double -epsilon -runs 5}}
\item Figure 9:\\
\small{\texttt{./test\_cpu -memory 128849018880 -img ../../images/img1s.ppm -img ../../images/img2s.ppm -img ../../images/img3s.ppm -img ../../images/img4s.ppm -img ../../images/img5s.ppm -img ../../images/img6s.ppm -img ../../images/img7s.ppm -img ../../images/img8s.ppm -img ../../images/img9s.ppm -img ../../images/img10s.ppm -float -single}\\
\texttt{./test\_cpu -memory 128849018880 -img ../../images/img1m.ppm -img ../../images/img2m.ppm -img ../../images/img3m.ppm -img ../../images/img4m.ppm -img ../../images/img5m.ppm -img ../../images/img6m.ppm -img ../../images/img7m.ppm -img ../../images/img8m.ppm -img ../../images/img9m.ppm -img ../../images/img10m.ppm -float -single}\\
\texttt{./test\_cpu -memory 128849018880 -img ../../images/img1s.ppm -img ../../images/img2s.ppm -img ../../images/img3s.ppm -img ../../images/img4s.ppm -img ../../images/img5s.ppm -img ../../images/img6s.ppm -img ../../images/img7s.ppm -img ../../images/img8s.ppm -img ../../images/img9s.ppm -img ../../images/img10s.ppm -float -epsilon -omp}\\
\texttt{./test\_cpu -memory 128849018880 -img ../../images/img1m.ppm -img ../../images/img2m.ppm -img ../../images/img3m.ppm -img ../../images/img4m.ppm -img ../../images/img5m.ppm -img ../../images/img6m.ppm -img ../../images/img7m.ppm -img ../../images/img8m.ppm -img ../../images/img9m.ppm -img ../../images/img10m.ppm -float -epsilon -omp}\\
\texttt{./test\_cpu -memory 257698037760 -img ../../images/img1l.ppm -img ../../images/img2l.ppm -img ../../images/img3l.ppm -img ../../images/img4l.ppm -img ../../images/img5l.ppm -img ../../images/img6l.ppm -img ../../images/img7l.ppm -img ../../images/img8l.ppm -img ../../images/img9l.ppm -img ../../images/img10l.ppm -float -epsilon -omp}\\
\texttt{/test\_gpu -memory 3221225472 -img ../../images/img1s.ppm -img ../../images/img2s.ppm -img ../../images/img3s.ppm -img ../../images/img4s.ppm -img ../../images/img5s.ppm -img ../../images/img6s.ppm -img ../../images/img7s.ppm -img ../../images/img8s.ppm -img ../../images/img9s.ppm -img ../../images/img10s.ppm -float -epsilon}\\
\texttt{/test\_gpu -memory 3221225472 -img ../../images/img1m.ppm -img ../../images/img2m.ppm -img ../../images/img3m.ppm -img ../../images/img4m.ppm -img ../../images/img5m.ppm -img ../../images/img6m.ppm -img ../../images/img7m.ppm -img ../../images/img8m.ppm -img ../../images/img9m.ppm -img ../../images/img10m.ppm -float -epsilon}\\
\texttt{/test\_gpu -memory 3221225472 -img ../../images/img1l.ppm -img ../../images/img2l.ppm -img ../../images/img3l.ppm -img ../../images/img4l.ppm -img ../../images/img5l.ppm -img ../../images/img6l.ppm -img ../../images/img7l.ppm -img ../../images/img8l.ppm -img ../../images/img9l.ppm -img ../../images/img10l.ppm -float -epsilon}\\
\texttt{/test\_gpu -memory 15032385536 -img ../../images/img1s.ppm -img ../../images/img2s.ppm -img ../../images/img3s.ppm -img ../../images/img4s.ppm -img ../../images/img5s.ppm -img ../../images/img6s.ppm -img ../../images/img7s.ppm -img ../../images/img8s.ppm -img ../../images/img9s.ppm -img ../../images/img10s.ppm -float -epsilon}\\
\texttt{/test\_gpu -memory 15032385536 -img ../../images/img1m.ppm -img ../../images/img2m.ppm -img ../../images/img3m.ppm -img ../../images/img4m.ppm -img ../../images/img5m.ppm -img ../../images/img6m.ppm -img ../../images/img7m.ppm -img ../../images/img8m.ppm -img ../../images/img9m.ppm -img ../../images/img10m.ppm -float -epsilon}\\
\texttt{/test\_gpu -memory 15032385536 -img ../../images/img1l.ppm -img ../../images/img2l.ppm -img ../../images/img3l.ppm -img ../../images/img4l.ppm -img ../../images/img5l.ppm -img ../../images/img6l.ppm -img ../../images/img7l.ppm -img ../../images/img8l.ppm -img ../../images/img9l.ppm -img ../../images/img10l.ppm -float -epsilon}}
\item Table 2: Requires Auction solver which is not included in this package.
\item Table 3: Data found in other tables except for limiting the number of threads to 8
\end{itemize}

\section{Own Project}
In order to use the software package in your own project, you need to include the \texttt{lap.h} file after setting the desired defines in your project. To get the same behaviour as the \texttt{test\_cpu}  program, use the following:
\begin{verbatim}
// enable OpenMP support
#ifdef _OPENMP
#  define LAP_OPENMP
#endif
// quiet mode
#define LAP_QUIET
// increase numerical stability for non-integer costs
#define LAP_MINIMIZE_V
\end{verbatim}
In case you would like to use GPU support, use the following as a starting point:
\begin{verbatim}
// enable CUDA support
#define LAP_CUDA
// OpenMP required for multiple devices
#define LAP_CUDA_OPENMP
// quiet mode
#define LAP_QUIET
// increase numerical stability for non-integer costs
#define LAP_MINIMIZE_V
\end{verbatim}

\subsection{High-Level Interface}
The high-level interface can be found in the \texttt{test\_cpu.cpp} and \texttt{test\_gpu.cu} files. The CPU functions are:
\begin{verbatim}
template <class SC, class TC, class CF, class TP>
void solveAdaptiveOMP(TP &start_time, int N1, int N2, CF &get_cost, int *rowsol, 
                      int entries, bool epsilon)
\end{verbatim}
and
\begin{verbatim}
template <class SC, class TC, class CF, class TP>
void solveAdaptive(TP &start_time, int N1, int N2, CF &get_cost, int *rowsol, 
                   int entries, bool epsilon)
\end{verbatim}
Where:
\begin{itemize}\raggedright
\item \texttt{SC} is the type used within the solver.
\item \texttt{TC} is the type for storing the cost values.
\item \texttt{TP \&start\_time} is starting time of the test returned by  \texttt{std::chrono::high\_resolution\_clock::now();}
\item \texttt{int N1} and \texttt{int N2} specify the size of the problem
\item \texttt{CF \&get\_cost} is the cost function lambda that takes two parameters \texttt{int x, int y} ($0 \leq x < N1$ and $0 \leq y < N2$) and returns the cost of type \texttt{TC}
\item \texttt{int *rowsol} points to the row solution being returned
\item \texttt{bool epsilon} enables out $\epsilon$-Pricing and should always be enabled.
\end{itemize}

The corresponding GPU functions are:
\begin{verbatim}
template <class SC, class TC, class CF, class STATE, class TP>
void solveCUDA(TP& start_time, int N1, int N2, CF& get_cost_gpu, STATE* state, 
               lap::cuda::Worksharing& ws, long long max_memory, int* rowsol, 
               bool epsilon, bool silent)
\end{verbatim}
and
\begin{verbatim}
template <class SC, class TC, class CF, class TP>
void solveTableCUDA(TP& start_time, int N1, int N2, CF& get_cost_cpu, 
                    lap::cuda::Worksharing& ws, long long max_memory, 
                    int* rowsol, bool epsilon, bool sequential, bool pinned, 
                    bool silent)
\end{verbatim}
The difference between these functions is that the first one uses a device lambda \texttt{CF \&get\_cost\_gpu} with parameters \texttt{(int x, int y, STATE \&state)} while the second function uses a regular cpu lambda as in the cpu code above.
Additional parameters are:
\begin{itemize}
\item A work sharing struct \texttt{ws}, constructed using \texttt{lap::cuda::Worksharing ws(int N1, int multiple, std::vector<int> \&devices, int max\_devices, bool silent);} with \texttt{multiple} usually set to 256 for better memory and thread alignment
\item \texttt{STATE *state} is a used defined per GPU state passed to the \texttt{get\_cost\_gpu} function, including pointer to memory locations used inside the device lambda
\item \texttt{long long max\_memory} defines how much memory should be allocated on a single GPU for holding the cost values (either cache or table)
\item \texttt{bool sequential} specifies if the \texttt{get\_cost\_cpu} lambda can only be called from a single thread
\item \texttt{bool pinned} if true, the entire CPU cost table will be stored in pinned memory
\end{itemize} 

\subsection{Low-Level Interface}
The low-level interface can be found in the \texttt{lap.h} include files. The single threaded CPU code consists of the following functions for solving the linear assignment and calculating the final costs:
\begin{verbatim}
namespace lap
{
  template <class SC, class CF, class I> void solve(
    int dim, CF &costfunc, I &iterator, int *rowsol, bool use_epsilon);
  template <class SC, class CF, class I> void solve(
    int dim, int dim2, CF &costfunc, I &iterator, int *rowsol, 
    bool use_epsilon);
  template <class SC, class CF> SC cost(
    int dim, CF &costfunc, int *rowsol);
  template <class SC, class CF> SC cost(
    int dim, int dim2, CF &costfunc, int *rowsol);
}
\end{verbatim}
The multi threaded CPU code uses the following interface:
\begin{verbatim}
namespace lap
{
  namespace omp
  {
    template <class SC, class CF, class I> void solve(
      int dim, CF &costfunc, I &iterator, int *rowsol, bool use_epsilon);
    template <class SC, class CF, class I> void solve(
      int dim, int dim2, CF &costfunc, I &iterator, int *rowsol, 
      bool use_epsilon);
    template <class SC, class CF> SC cost(
      int dim, CF &costfunc, int *rowsol);
    template <class SC, class CF> SC cost(
      int dim, int dim2, CF &costfunc, int *rowsol);
  }
}
\end{verbatim}
The GPU version of the interface is as follows:
\begin{verbatim}
namespace lap
{
  namespace cuda
  {
    template <class SC, class TC, class CF, class I> void solve(
      int dim, CF &costfunc, I &iterator, int *rowsol, bool use_epsilon);
    template <class SC, class TC, class CF, class I> void solve(
      int dim, int dim2, CF &costfunc, I &iterator, int *rowsol, 
      bool use_epsilon);
    template <class SC, class TC, class CF> SC cost(
      int dim, CF &costfunc, int *rowsol, cudaStream_t stream);
    template <class SC, class TC, class CF> SC cost(
      int dim, int dim2, CF &costfunc, int *rowsol, cudaStream_t stream);
  }
}
\end{verbatim}

Please refer to the same for additional helper classes that can be used for the low-level interface.

%\input{introduction.tex}
%\input{related.tex}
%\input{algorithm.tex}
%\input{large.tex}
%\input{results.tex}
%\input{conclusion.tex}
% don't really want to have these...
%\input{appendix.tex}

%\bibliographystyle{ACM-Reference-Format}
%\bibliography{refs}

\end{document}
