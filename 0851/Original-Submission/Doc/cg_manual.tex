\documentclass [12pt] {article}
\usepackage[dvips]{graphics}
\usepackage{color}
\usepackage{bm}
\usepackage{amsfonts}
\newcommand{\tr}{^{\sf T}}
\newcommand{\m}[1]{{\bf{#1}}}
\newcommand{\g}[1]{\bm #1}
%-------------------------------------------------------------------------------
% get epsf.tex file, for encapsulated postscript files:
\input epsf
%-------------------------------------------------------------------------------
% macro for Postscript figures the easy way
% usage:  \postscript{file.ps}{scale}
% where scale is 1.0 for 100%, 0.5 for 50% reduction, etc.
%
\newcommand{\postscript}[2]
{\setlength{\epsfxsize}{#2\hsize}
\centerline{\epsfbox{#1}}}
%-------------------------------------------------------------------------------
 

\begin{document}

\medskip
\title{{\bf
CG\_DESCENT Version 1.1 \\
User's Guide
}\thanks{
This material is based upon work supported
by the National Science Foundation under Grant No. CCR-0203270.
}
}
\author{
        William W. Hager\thanks{hager@math.ufl.edu,
        http://www.math.ufl.edu/$\sim$hager,
        PO Box 118105,
        Department of Mathematics,
        University of Florida, Gainesville, FL 32611-8105.
        Phone (352) 392-0281. Fax (352) 392-8357.}
\and
Hongchao Zhang\thanks{
        hzhang@math.ufl.edu,
        http://www.math.ufl.edu/$\sim$hzhang,
        PO Box 118105,
        Department of Mathematics,
        University of Florida, Gainesville, FL 32611-8105.}
}
\date{December 10, 2004}

\maketitle

\newpage
%-------------------------------------------------------------------------------
\section{Introduction}
%-------------------------------------------------------------------------------
This document provides a guide for using the Fortran 77 code
{\sc cg\_descent},
an implementation of the conjugate gradient algorithm for which
the search directions are always descent directions.
The code along with the papers \cite{hz, hz2}
developing the algorithm and comparing its convergence
properties to that of other algorithms for unconstrained optimization
are posted at the following web site:
\begin{center}
http://www.math.ufl.edu/$\sim$hager/papers/CG
\end{center}
In this manual, we explain the design of the software and how to use it.

The conjugate gradient method is an approach for solving an unconstrained
optimization problem of the following form:
%
\[
\min \; \{ f (\m{x}) : \m{x} \in \Re^n \},
\]
%
where $f: \mathbb{R}^n \mapsto \mathbb{R}$ is continuously differentiable.
The iterates $\m{x}_k$, $k \ge 0$,
in conjugate gradient methods satisfy the recurrence
%
\[
\m{x}_{k+1} = \m{x}_k + \alpha_k \m{d}_k ,
\]
%
where the stepsize $\alpha_k$ is positive,
and the directions $\m{d}_k$ are generated by the rule:
%
\[
\m{d}_{k+1} = -\m{g}_{k+1} + \beta_k \m{d}_k, \quad \m{d}_0 = -\m{g}_0.
\]
%
In {\sc cg\_descent}, we make the following special choice for the
parameter $\beta_k$:
%
\begin{eqnarray*}
\beta_k &=& \max \left\{
B_k , \eta_k \right\}, \quad \mbox{where} \\
\eta_k &=&
\frac{-1}{\|\m{d}_k\| \min \{\eta, \|\m{g}_k \|\}} , \\
B_k &=&
\frac{1}{\m{d}_k\tr \m{y}_k}
\left( \m{y}_k - 2\m{d}_k\frac{\|\m{y}_k\|^2}
{\m{d}_k\tr\m{y}_k} \right)\tr\m{g}_{k+1} .
\end{eqnarray*}
%
Here $\eta > 0$ is a user specified constant.

The stepsize $\alpha_k$ is computed by a line search routine
that exploits a combination of secant and bisection steps for
fast convergence.
The line search is terminated when the
Wolfe conditions \cite{w69,w71} are satisfied.
Defining $\phi (\alpha) = f (\m{x}_k + \alpha \m{d}_k)$,
these conditions are:
%
\begin{equation}\label{strongw}
\delta \phi ' (0) \ge \frac{\phi(\alpha_k) - \phi (0)}{\alpha_k} \quad
\mbox{and} \quad
\phi ' (\alpha_k) \ge \sigma \phi ' (0) ,
\end{equation}
%
where $0 < \delta \le \sigma < 1$.

In \cite{hz} we observe that the first condition in (\ref{strongw})
is difficult to implement numerically
since the subtraction $\phi(\alpha_k) - \phi (0)$
is relatively inaccurate near a local minimum.
To cope with this numerical inaccuracy,
we introduce the approximate Wolfe conditions
in \cite{hz} and \cite{hz2}:
%
\begin{equation}\label{approx-wolfe}
(2\delta -1 ) \phi ' (0) \ge \phi ' (\alpha_k) \ge \sigma \phi ' (0) ,
\end{equation}
%
where $0 < \delta < 1/2$ and $\delta \le \sigma < 1$.
The first inequality in (\ref{approx-wolfe}) is an approximation
to the first inequality in (\ref{strongw}).
In a neighborhood of a local minimum, this approximation can often
be evaluated more accurately than the original condition.
The approximate Wolfe conditions are employed only when
%
\begin{equation}\label{function_accuracy}
\phi (\alpha_k) \le \phi (0) +  \epsilon_k ,
\end{equation}
%
where $\epsilon_k$ is an estimate for the error in the function value
at iteration $k$.
We incorporate the following possible expressions for the
error in the function value:
%
\begin{equation}\label{eps_k}
\epsilon_k = \epsilon C_k  \quad \mbox{or} \quad
\epsilon_k = \epsilon ,
\end{equation}
%
where $\epsilon$ is a small, user specified parameter, and $C_k$ is
generated by the following recurrence:
\begin{equation}\label{Ck}
\left.
\begin{array}{ll}
Q_{k} = 1 + Q_{k-1} \Delta , &\; Q_{-1} = 0 , \\
C_{k} = C_{k-1} + (|f(\m{x}_{k})| - C_{k-1})/Q_k, &\; C_{-1} = 0. \\
\end{array} \right\}
\end{equation}
Here $\Delta \in [0,1]$ is a parameter used in the averaging of the
previous absolute function values.
As $\Delta$ approaches 0, we give more weight to the most recent function
values.
Since there is no theory to guarantee convergence when using the
approximate Wolfe conditions, one of the code's parameters allows
the user to employ only the standard Wolfe conditions.
But by default, the code uses the approximate Wolfe conditions when
(\ref{function_accuracy}) holds since we observe
greater accuracy and efficiency when these conditions are utilized.
Alternatively, by setting the parameter {\sc AWolfe} to false,
the code initially computes points satisfying the usual Wolfe conditions
until the following inequality is satisfied:
%
\begin{equation}\label{omega}
|f(\m{x}_{k+1}) - f(\m{x}_{k})| \le \omega C_k .
\end{equation}
%
Thereafter, the code switches to the approximate Wolfe conditions.
%-------------------------------------------------------------------------------
\section{Running the code}
%-------------------------------------------------------------------------------

{\sc cg\_descent}
requires a parameter file {\sc cg.parm}, which should be placed
in the same directory where the code is run, and subroutines to evaluate
the function $f (\m{x})$ and the gradient $\nabla f (\m{x})$.
The arguments of the subroutine are the following:
\begin{enumerate}
\item
{\sc grad\_tol} (double) -- specifies the desired accuracy in the solution.
If {\sc StopRule}
in {\sc cg.parm} is true, then the code terminates when
%
\begin{equation}\label{stop1}
\|\nabla f (\m{x})_k\|_{\infty} \le
\max \{
\mbox{\sc grad\_tol}, \mbox{\sc StopFac} * \|\nabla f (\m{x}_0)\| \} ,
\end{equation}
%
where $\| \cdot\|_{\infty}$
denotes the sup-norm (maximum absolute component of the vector).
If {\sc StopRule} is false, then the code terminates when
%
\begin{equation}\label{stop2}
\|\nabla f (\m{x})_k\|_{\infty} \le \mbox{\sc grad\_tol}(1 + |f(\m{x}_k)|).
\end{equation}
%
The code also terminates when
%
\begin{equation}\label{stop3}
-\alpha_k \phi ' (0) \le \mbox{\sc feps}|f(\m{x}_{k+1})|,
\end{equation}
%
where the default value of {\sc feps} in {\sc cg.parm} is 0.d0.
\item
{\sc x} (double) -- array of length $n$ containing the starting guess
on input and computed minimizer on output.
\item
{\sc n} (int) -- problem dimension.
\item
{\sc cg\_value} (external) -- name of the routine to evaluate the
cost function $f(\m{x})$.
{\sc cg\_value (f, x, n)} puts the value of the cost function in
the double precision variable {\sc f},
where {\sc x} is a double precision array containing the vector $\m{x}$.
\item
{\sc cg\_grad} (external) -- name of the routine to evaluate the
gradient $\nabla f (\m{x})$.
{\sc cg\_grad (g, x, n)} puts the gradient of the cost function in
the double precision array {\sc g}, where {\sc x} is a double precision array
containing the vector $\m{x}$.
\item
{\sc status} (int) -- the value indicates how the code terminates.
As explained below,
a nonzero value for status indicates abnormal termination.
\item
{\sc gnorm} (double) --
if {\sc Step} in {\sc cg.parm} is .true., then {\sc gnorm} contains
a guess for the line search minimizer at $k = 0$;
in other words, {\sc gnorm} is the
user's approximation to a value of $\alpha > 0$ that minimizes
$f (\m{x}_0 - \alpha \m{g}_0)$.
If {\sc Step} is .false., then {\sc gnorm} is ignored at startup,
and the code generates its own starting guess.
On termination, {\sc gnorm} contains $\|\nabla f (\m{x}_k)\|_{\infty}$.
\item
{\sc f} (double) -- value of $f (\m{x}_k)$ at the final iteration.
\item
{\sc iter} (int) -- number of iterations that were performed.
\item
{\sc nfunc} (int) -- number of times the function was evaluated.
\item
{\sc ngrad} (int) -- number of times the gradient was evaluated.
\item
{\sc d} (double) -- work array of length $n$ containing the search direction.
\item
{\sc g} (double) -- work array of length $n$ containing the gradient.
\item
{\sc xtemp} (double) -- work array of length $n$ containing
$\m{x}_k + \alpha \m{d}_k$.
\item
{\sc gtemp} (double) -- work array of length $n$ containing
$\nabla f ( \m{x}_k + \alpha \m{d}_k)$.
\end{enumerate}

The values of status and their meaning are list below:
\begin{itemize}
\item [0 --]
The convergence tolerance specified by {\sc grad\_tol} was satisfied.
\item [1 --]
Terminated with $-\alpha_k \phi' (0) \le$ {\sc feps}$|f(\m{x}_{k+1})|$.
\item [2 --]
The maximum number of iterations exceeded the limit
{\sc maxit} specified through {\sc cg.parm}.
\item [3 --]
The slope $\phi ' (\alpha)$ is always negative for a sequence of values
of $\alpha$ becoming very large.
\item [4 --]
The number of secant iterations during the line search exceeds
the value of {\sc nsecant} (default 50) given in {\sc cg.parm}.
\item [5 --]
The current search direction is not a direction of descent.
According to the theory in \cite{hz, hz2},
the search direction should be a direction of descent for $f$.
\item [6 --]
The line search has failed in the initialization part of the line search.
\item [7 --]
The line search has failed in the bisection step.
\item [8 --]
The line search has failed in the interval update routine.
\end{itemize}

We illustrate the use of {\sc cg\_descent} with the problem:
%
\[
\min \; \sum_{i = 1}^n e^{x_i} - x_i \sqrt{i} ,
\]
%
and the starting guess $x_i = 1$ for each $i$.
The following code shows how to
set up the problem and invoke the subroutine:
\begin{tabbing}
\hspace{2em} \= \hspace{2em} \= \hspace{1em} \= \hspace{2em} \= \kill
\>\>\> \sc integer m \\
\>\>\> \sc parameter (m = 100000) \\
\>\>\> \sc double precision x (m), d (m), g (m), xtemp (m), gtemp (m), \\
\>\>\&\> \>\sc gnorm, f \\
\>\>\> \sc integer i, n, status, iter, nfunc, ngrad \\
\>\>\> \sc external myvalue, mygrad \\
\>\>\> \sc n = 100 \\
\>\>\> \sc do i = 1, n \\
\>\>\>\> \sc x (i) = 1.d0 \\
\>\>\> \sc enddo \\
\>\>\> \sc call cg\_descent (1.d$-$8, x, n, myvalue, mygrad, status,\\
\>\>   \&\>\>  \sc     gnorm, f, iter, nfunc, ngrad, d, g, xtemp, gtemp) \\
\>\>\> \sc end \\
\>\\
\>\>\> \sc subroutine myvalue (f, x, n) \\
\>\>\>  \sc double precision x (1), f, t \\
\>\>\>\sc  f = 0.d0 \\
\>\>\>  \sc do i = 1, n \\
\>\>\>\> \sc t = i \\
\>\>\>\> \sc t = dsqrt (t) \\
\>\>\>\> \sc f = f +  dexp (x (i)) $-$ t*x (i) \\
\>\>\> \sc enddo \\
\>\>\> \sc return \\
\>\>\> \sc end \\
\\
\>\>\> \sc subroutine mygrad (g, x, n) \\
\>\>\> \sc double precision g (1), x (1), t \\
\>\>\> \sc do i = 1, n \\
\>\>\>\> \sc t = i \\
\>\>\>\> \sc t = dsqrt (t) \\
\>\>\>\> \sc g (i) = dexp (x (i)) $-$ t \\
\>\>\> \sc enddo \\
\>\>\> \sc return \\
\>\>\> \sc end
\end{tabbing}

The following output is generated when the code is run:
\begin{tabbing}
\hspace{2em} \= \kill
\> \sc Termination status:  0 \\
\> \sc Convergence tolerance for gradient satisfied \\
\> \sc absolute largest component of gradient: 0.7200D$-$08 \\
\> \sc function value:   $-$653.07867273306 \\
\> \sc cg iterations:  31 \\
\> \sc function evaluations:  54 \\
\> \sc gradient evaluations:  43
\end{tabbing}

The algorithm parameters are specified in
the file {\sc cg.parm}, which the code reads at the start of execution.
Hence, this file should be placed in the directory where the code is run.
A list of the parameters and their default values appears in Table \ref{parm}.
We now give an overview of these parameters:
\begin{table}
\begin{center}
\begin{tabular}{c|c||c|c}
Value & Parameter & Value & Parameter\\
\hline
.1d0      &     $\delta$ & 1.0d0     &     {\sc restart\_fac}\\
.9d0      &     $\sigma$ & 500.d0    &     {\sc maxit\_fac} \\
1.d$-$6     &     $\epsilon$&  0.d0      &     {\sc feps}\\
.5d0      &     $\theta$ & .7d0      &     {\sc Qdecay}\\
.66d0     &     $\gamma$ & 50        &     {\sc nexpand}\\
5.0d0     &     $\rho$ & 50        &     {\sc nsecant}\\
.01d0     &     $\eta$ & .true.        &     {\sc PertRule}\\
.01d0     &     $\psi_0$&  .true.    &     {\sc QuadStep}\\
.1d0      &     $\psi_1$ & .false    &     {\sc PrintLevel}\\
2.d0      &     $\psi_2$&  .true.    &     {\sc PrintFinal}\\
1.d$-$12    &     {\sc QuadCutOff} & .true.   &     {\sc StopRule}\\
.0d0 & {\sc StopFac} & .true.    &     {\sc AWolfe} \\
1.d$-$3 & {\sc AWolfeFac} & .false.   &     {\sc Step} \\
& & .false. & {\sc debug}
\end{tabular}
\end{center}
\caption{Parameters in file {\sc cg.parm} and their default values.}
\label{parm}
\end{table}
\begin{itemize}
\item
The maximum number {\sc maxit} of iterations allowed by the code is
{\sc maxit\_fac}*{\sc n}, where {\sc n} is the problem dimension.
By default, {\sc maxit} is 500*{\sc n}.
We also impose limits in the line search.
The maximum number of secant steps is {\sc nsecant} and the maximum
number of expansions when we try to find an initial bracketing
interval in the line search is {\sc nexpand}.
\item
The code automatically computes an initial step for the
very first conjugate gradient iteration.
This automated guess can be crude.
If the user wishes to provide the starting guess for a minimizer of
$f(\m{x}_0 - \alpha \m{g}_0)$ over $\alpha > 0$, then set the parameter
{\sc Step} to .true., and in this case,
the value of the {\sc gnorm} argument of {\sc cg\_descent}
should be the initial guess.
\item
If {\sc AWolfe} is true, then the codes terminates the line search
whenever either the ordinary Wolfe conditions (\ref{strongw})
or the approximate Wolfe conditions (\ref{approx-wolfe}) are
satisfied along with (\ref{function_accuracy}).
If {\sc AWolfe} is false, then the code 
initially computes points satisfying the usual Wolfe conditions
until the the inequality (\ref{omega}) is satisfied.
Thereafter, {\sc AWolfe} is set to true.
By default, the code tests the approximate Wolfe conditions when
(\ref{function_accuracy}) holds.
The parameter $\omega$ in (\ref{omega}) is the same
as the parameter {\sc AWolfeFac} in the parameter file.
To completely by-pass the approximate Wolfe conditions,
the value of {\sc AWolfe}
is set to false and {\sc AWolfeFac} is set to 0.
\item
The parameter $\epsilon$ is used in (\ref{function_accuracy})
to obtain an estimate $\epsilon_k$ for the error in the function value.
This estimate for the error governs when we use the
approximate Wolfe conditions, and it enters into the update rules in 
the line search.
The parameter $\Delta$ in (\ref{Ck}) is the same as the
parameter {\sc Qdecay} in the parameter file.
\item
If {\sc PertRule} is true, then we take $\epsilon_k = \epsilon C_k$
in (\ref{eps_k}).
Otherwise, we take $\epsilon_k = \epsilon$
\item
If {\sc debug} is true, then in each iteration, we check whether
$f(\m{x}_{k+1}) \le f (\m{x}_k) + 10^{-10} C_k$, where $C_k$ is
generated in (\ref{Ck}).
When this inequality is violated, execution stops.
\item
By default, execution is terminated when (\ref{stop1}) holds.
By setting the parameter {\sc StopRule} to false,
execution terminates when (\ref{stop2}) holds.
The code also terminates when (\ref{stop3}) holds.
By default {\sc feps} is 0.d0, and the condition (\ref{stop3}) has no effect.
The user may wish to terminate execution when
the change in function value becomes negligible, in which case {\sc feps}
should be set to a small positive value, typically much
smaller than the machine epsilon.
\item
By default, the code prints the results of the run, excluding the value
of $\m{x}$.
To by-pass this printout, set {\sc PrintFinal} to false.
By default, the code delays all printing until the end of the run.
To obtain detailed information concerning the line search and the convergence,
set {\sc PrintLevel} to true.
\item
As explained in \cite{hz2}, conjugate gradient methods preserve their $n$-step
convergence property when the line search involves a ``quadratic step.''
By default, the code attempts to make such a quadratic step.
To deactivate this step, set {\sc QuadStep} to .false.~.
The quadratic step is only attempted when the relative change in the
function value for consecutive iterations is larger than {\sc QuadCutOff}.
If the relative change is tiny, then the quadratic step can be inaccurate,
and it is skipped.
\item
The number {\sc nrestart} of conjugate gradient iterations before
performing the restart
$\m{d}_k = - \m{g}_k$ is
{\sc restart\_fac}*{\sc n}.
By default, {\sc restart\_fac} is 1 and {\sc nrestart} is {\sc n}.
\item
In computing an initial bracketing interval in the line search,
we evaluate $\phi (\alpha)$ for a series of $\alpha$'s, each new value
of $\alpha$ is $\rho$ times its predecessor.
The default value for $\rho$ is 5.
In some cases, however,
it could be necessary to decrease $\rho$, while
preserving the relation $\rho > 1$.
\item
The parameters $\delta$, $\sigma$, $\theta$, $\gamma$, and $\eta$
are connected with the line search, termination
conditions, and the formula for $\beta_k$.
These parameters could be fine tuned to improve performance in some
applications.
The following inequalities should be maintained:
$0 < \delta < .5$, $\delta \le \sigma < 1$, $\eta > 0$, $\epsilon \ge 0$,
$0 < \theta < 1$, and $0 < \gamma < 1$.
\item
The parameters $\psi_0$, $\psi_1$ and $\psi_2$ are all used
in generating the initial stepsize in the line search,
as explained in \cite{hz2}.
\end{itemize}

%-------------------------------------------------------------------------------
\section{Trouble shooting}
\label{trouble}
%-------------------------------------------------------------------------------
We now discuss the error messages and their possible cause.
If the argument {\sc grad\_tol} of {\sc cg\_descent} is so small that the
tolerance cannot be achieved (due to rounding errors in the evaluation
of the function and its gradient), then the code can terminate in several
abnormal ways.
For example,
the iterations could continue until the iteration
limit {\sc maxit} is reached;
also, numerical errors in the line search might lead to termination.
In the example given above, when we change the argument 1.d$-$8 to 1.d$-$20,
we generate the following output:
\begin{tabbing}
\hspace{2em} \= \kill
\> \sc Termination status:  4 \\
\> \sc Line search fails, too many secant steps \\
\> \sc   - your tolerance (grad\_tol = 0.1000D$-$19) is too strict \\
\> \sc absolute largest component of gradient: 0.1776D$-$14 \\
\> \sc function value:   $-$653.07867273306 \\
\> \sc cg iterations:  217 \\
\> \sc function evaluations:  532 \\
\> \sc gradient evaluations:  707
\end{tabbing}
Observe that the gradient is relatively small, however, we did not
reach the requested tolerance 1.d$-$20.

The parameter {\sc feps} in {\sc cg.parm}
provides another mechanism to terminate
execution when the code has essentially attained the highest
possible accuracy.
If we set {\sc grad\_tol}
to 1.d$-$20 and we change the value of {\sc feps} in
{\sc cg.parm} to 1.d$-$25, then the the following output is generated:
\begin{tabbing}
\hspace{2em} \= \kill
\> \sc Termination status:  1 \\
\> \sc Terminating since change in function value $\le$ feps*$|$f$|$ \\
\> \sc absolute largest component of gradient: 0.1910D$-$13 \\
\> \sc function value:   $-$653.07867273306 \\
\> \sc cg iterations:  52 \\
\> \sc function evaluations:  75 \\
\> \sc gradient evaluations:  85
\end{tabbing}
The default value for {\sc feps} is 0.d0, in which case this termination
condition has no effect.

The parameter $\epsilon$ in {\sc cg.parm}
is used
to obtain an estimate $\epsilon_k$
in (\ref{function_accuracy})
for the error in the function value.
This estimate is used in the
approximate Wolfe conditions and in the update rules for a bracket
interval in the line search.
If $\epsilon_k$ is too small, then an error can arise in the line search
near a local minimizer;
numerically, we can have
$\phi (\alpha) > \phi (0) + \epsilon_k$,
while with exact arithmetic, 
$\phi (\alpha) < \phi (0)$.
Hence, the code thinks the function looks like the graph depicted
in Figure \ref{rounding},
%
\begin{figure}
\begin{center}
\postscript{rounding.eps}{.7}
\caption{Rounding errors near a local minimum leading to an artificial
hump in the numerical $f$}
\label{rounding}
\end{center}
\end{figure}
%
when the actual function is monotone decreasing
on the interval $[0, \alpha]$.
In other words, the hump seen in Figure \ref{rounding}
may be due to rounding errors.
This discrepancy between numerical function and true
function leads to an error in the line search.
For example, setting the parameter $\epsilon$ in {\sc cg.parm} to 0.d0 yields
the following output:
\begin{tabbing}
\hspace{2em} \= \kill
\> \sc Termination status:  8 \\
\> \sc Line search fails \\
\> \sc Possible causes of this error message: \\
\> \sc   - your tolerance (grad\_tol = 0.1000D$-$07) is too strict \\
\> \sc   - your gradient routine has an error \\
\> \sc   - the parameter epsilon in cg.part is too small \\
\> \sc absolute largest component of gradient: 0.8624D$-$07 \\
\> \sc function value:   $-$653.07867273306 \\
\> \sc cg iterations:  29 \\
\> \sc function evaluations:  103 \\
\> \sc gradient evaluations:  90
\end{tabbing}
The default value $10^{-6}$
of $\epsilon$ in {\sc cg.parm} is
usually large enough to prevent this type of failure, except in
cases where the function vanishes at the computed local minimum.
When the function vanishes, the first form of $\epsilon_k$ in
(\ref{function_accuracy}) approaches zero as the iterations convergence,
while the actual error typically does not approach zero.
In this case, where the function vanishes at the local minimum,
you may need to use the second form for the error, which is
activated by setting to .true. the parameter {\sc ERule} in {\sc cg.parm}.
This problem connected with the estimation of the error in function value
arises only when a high accuracy solution is computed.
In the example just given, where we set $\epsilon =$ 0.d0, we still
computed a solution for which the absolute largest component of the
gradient is less than $10^{-7}$ and the computed cost
is correct to 14 significant digits.

If the code to evaluate the gradient of the cost function has an error,
then the line search can fail.
For our previous example,
changing the minus sign to a plus sign in the code to evaluate the
gradient yields:
\begin{tabbing}
\hspace{2em} \= \kill
\> \sc Termination status:  6 \\
\> \sc Line search fails \\
\> \sc Possible causes of this error message: \\
\> \sc   - your tolerance (grad\_tol = 0.1000D$-$07) is too strict \\
\> \sc   - your gradient routine has an error \\
\> \sc   - the parameter epsilon in cg.part is too small \\
\> \sc absolute largest component of gradient: 0.1272D+02 \\
\> \sc function value:   $-$399.63436462248 \\
\> \sc cg iterations:  1 \\
\> \sc function evaluations:  53 \\
\> \sc gradient evaluations:  52
\end{tabbing}

One way to ensure that the gradient routine is correct is to use
the ADIFOR software to automatically transform
the routine for evaluating the cost function into a routine
for evaluating the gradient.
Alternatively, if your gradient routine is hand-coded, you can use 
finite difference approximations to check whether the code is correct.
That is,
%
\begin{equation}\label{finitediff}
(\nabla f (\m{x}))_i = \frac {f(\m{x} + s \m{e}_i) - f (\m{x})}
{s} + O(s) ,
\end{equation}
%
where $\m{e}_i$ is the $i$-th column of the identity matrix.
By taking a sequence of $s$'s approaching zero, the finite difference
approximation should first approach the true gradient component,
then diverge due to numerical errors connected with the evaluation of the
numerator of (\ref{finitediff}).
In the following code, we check the first component of the gradient
in our model problem:
\begin{tabbing}
\hspace{2em} \= \hspace{2em} \= \hspace{1em} \= \hspace{2em} \= \kill
\>\>\> \sc parameter (m = 100000) \\
\>\>\> \sc double precision x (m), g (m), f, newf,\\
\>\>\&\> \>\sc t, rel, delta, approx \\
\>\>\> \sc integer i, n \\
\>\>\> \sc external myvalue, mygrad \\
\>\>\> \sc n = 100 \\
\>\>\> \sc do i = 1, n \\
\>\>\>\> \sc x (i) = 1.d0 \\
\>\>\> \sc enddo\\
\>\>\> \sc call myvalue (f, x, n)\\
\>\>\> \sc call mygrad (g, x, n)\\
\>\>\> \sc delta = 1.e$-$1\\
\>\>\> \sc t = x (1)\\
\>\>\> \sc do i = 1, 12\\
\>\>\>\> \sc x (1) = t + delta\\
\>\>\>\> \sc call myvalue (newf, x, n)\\
\>\>\>\> \sc approx = (newf $-$ f)/delta\\
\>\>\>\> \sc rel = dabs ((approx $-$ g (1)) / g (1))\\
\>\>\>\> \sc write (6, *) delta, rel, approx, g(1)\\
\>\>\>\> \sc delta = delta/10\\
\>\>\> \sc enddo\\
\>\>\> \sc x (1) = t\\
\>\>\> \sc end
\end{tabbing}

The output generated by this code appears in Table \ref{out1}.
Observe that for $s$ between $10^{-1}$ and $10^{-7}$, the relative
error in the finite difference approximation decreases as it approaches
the value of g~(1), while for smaller $s$, the error increases.
\begin{table}
\begin{center}
\begin{tabular}{cccc}
{\sc s} & Relative Error & Approximation & {\sc g} (1)\\
\hline
0.100E+00 & 0.818E$-$01 & 0.18588419549E+01 & 0.17182818285E+01 \\
0.100E$-$01 & 0.794E$-$02 & 0.17319186558E+01 & 0.17182818285E+01 \\
0.100E$-$02 & 0.791E$-$03 & 0.17196414225E+01 & 0.17182818285E+01 \\
0.100E$-$03 & 0.791E$-$04 & 0.17184177472E+01 & 0.17182818285E+01 \\
0.100E$-$04 & 0.791E$-$05 & 0.17182954196E+01 & 0.17182818285E+01 \\
0.100E$-$05 & 0.807E$-$06 & 0.17182832153E+01 & 0.17182818285E+01 \\
0.100E$-$06 & 0.212E$-$06 & 0.17182821921E+01 & 0.17182818285E+01 \\
0.100E$-$07 & 0.220E$-$05 & 0.17182856027E+01 & 0.17182818285E+01 \\
0.100E$-$08 & 0.220E$-$04 & 0.17183197087E+01 & 0.17182818285E+01 \\
0.100E$-$09 & 0.551E$-$04 & 0.17183765522E+01 & 0.17182818285E+01 \\
0.100E$-$10 & 0.237E$-$02 & 0.17223555915E+01 & 0.17182818285E+01 \\
0.100E$-$11 & 0.255E$-$01 & 0.17621459847E+01 & 0.17182818285E+01 \\
\hline
\end{tabular}
\end{center}
\caption{Output generated by correct gradient routine}
\label{out1}
\end{table}
On the other hand, for the erroneous gradient code,
obtained by replacing the minus sign in the gradient code by a plus sign,
we obtain the results given in Table \ref{out2}.
Of course, you should check all components of the gradient,
not just the first component.

\begin{table}
\begin{center}
\begin{tabular}{cccc}
{\sc s} & Relative Error & Approximation & {\sc g} (1) \\
\hline
0.100E+00& 0.500E+00 & 0.18588419549E+01 & 0.37182818285E+01 \\
0.100E$-$01& 0.534E+00 & 0.17319186558E+01 & 0.37182818285E+01 \\
0.100E$-$02& 0.538E+00 & 0.17196414225E+01 & 0.37182818285E+01 \\
0.100E$-$03& 0.538E+00 & 0.17184177472E+01 & 0.37182818285E+01 \\
0.100E$-$04& 0.538E+00 & 0.17182954196E+01 & 0.37182818285E+01 \\
0.100E$-$05& 0.538E+00 & 0.17182832153E+01 & 0.37182818285E+01 \\
0.100E$-$06& 0.538E+00 & 0.17182821921E+01 & 0.37182818285E+01 \\
0.100E$-$07& 0.538E+00 & 0.17182856027E+01 & 0.37182818285E+01 \\
0.100E$-$08& 0.538E+00 & 0.17183197087E+01 & 0.37182818285E+01 \\
0.100E$-$09& 0.538E+00 & 0.17183765522E+01 & 0.37182818285E+01 \\
0.100E$-$10& 0.537E+00 & 0.17223555915E+01 & 0.37182818285E+01 \\
0.100E$-$11& 0.526E+00 & 0.17621459847E+01 & 0.37182818285E+01 \\
\hline
\end{tabular}
\end{center}
\caption{Output generated by erroneous gradient routine}
\label{out2}
\end{table}
\begin{thebibliography}{99}
\bibitem{hz}
{\sc W.\ W.\ Hager and H.\ Zhang,}
{\it A New Conjugate Gradient Method with
Guaranteed Descent and an Efficient Line Search},
Department of Mathematics, University of Florida, November 17, 2003
(revised July 10, 2004).

\bibitem{hz2}
{\sc W.\ W.\ Hager and H.\ Zhang,}
{\it CG\_DESCENT, a Conjugate Gradient Method
with Guaranteed Descent},
Department of Mathematics, University of Florida, January 12, 2004
(revised December 10, 2004).

%\bibitem {ray97}
%{\sc M. Raydan},
%{\it The Barzilai and Borwein gradient method for the large
%scale unconstrained minimization problem},
%SIAM J. Optim., 7 (1997), pp. 26--33.

\bibitem{w69}
{\sc P.\ Wolfe},
{\it Convergence conditions for ascent methods},
SIAM Rev., 11 (1969), pp.\ 226--235.

\bibitem{w71}
{\sc P.\ Wolfe},
{\it Convergence conditions for ascent methods II: some corrections},
SIAM Rev., 13 (1971), pp.\ 185--188.

\end {thebibliography}
\end{document}
